from llama_index.core import VectorStoreIndex, get_response_synthesizer
from llama_index.core.query_engine import RetrieverQueryEngine
from src.inference.custom_retriever import TypeDBHybridRetriever
import os

# Mock OpenAI Key if not set (for demo purposes without hitting API if we mock the synthesizer too, 
# but LlamaIndex needs a key usually. We will rely on user having one or just demonstrating the retrieval part).
# os.environ["OPENAI_API_KEY"] = "sk-..." 

def run_agent_demo():
    print("ğŸ¤– Initializing Riemann AI Agent...")
    
    # 1. Initialize Custom Retriever
    retriever = TypeDBHybridRetriever()
    
    # 2. Configure Response Synthesizer (The part that generates the final answer)
    # Using 'compact' mode to just concatenate the retrieved texts for now if direct LLM call is tricky without key.
    # In a real scenario: synthesizer = get_response_synthesizer(response_mode="compact")
    
    # 3. Create Query Engine
    # query_engine = RetrieverQueryEngine(retriever=retriever, response_synthesizer=synthesizer)
    
    # For this demo, let's just run the retrieval manually to show it working within the LlamaIndex structure
    # since we might not have a valid OpenAI key in this environment.
    
    query_str = "Aliceê°€ ì‘ì„±í•œ ë¬¸ì„œë“¤ì— ëŒ€í•´ ì•Œë ¤ì¤˜"
    print(f"\nğŸ—£ï¸ User Query: {query_str}")
    
    nodes = retriever.retrieve(query_str)
    
    print(f"\nğŸ“ [Agent Response Generation]")
    print(f"Retrieved {len(nodes)} context chunks for LLM synthesis.")
    for i, node in enumerate(nodes):
        print(f"\n--- Context Chunk {i+1} ---")
        print(node.node.get_text()[:200] + "...")

    # Simulated Final Answer
    if nodes:
        print("\nğŸ’¡ [Simulated LLM Output]:")
        print(f"Alice Engineerë‹˜ì€ ì´ {len(nodes)}ê°œì˜ ë¬¸ì„œë¥¼ ì‘ì„±í–ˆìŠµë‹ˆë‹¤.")
        print("ì²« ë²ˆì§¸ëŠ” 'Project Riemann Architecture Overview'ë¡œ, TypeDBì™€ Postgresë¥¼ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜ë¥¼ ì„¤ëª…í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
        print("ë‘ ë²ˆì§¸ëŠ” 'Q1 2026 Roadmap'ì´ë©°, LlamaIndex í†µí•© ë° Airflow íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ê³„íšì„ ë‹´ê³  ìˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    run_agent_demo()
